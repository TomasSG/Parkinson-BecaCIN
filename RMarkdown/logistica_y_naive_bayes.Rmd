---
title: "Regresión Logística y Naive Bayes"
output:
  html_notebook:
    toc: yes
---

# Bibliotecas

```{r}
library(caret)
library(pROC)
library(e1071)
library(tidyverse)
library(ggpubr)
library(scales)

source("./R/Utils.R")
```


# Variables Globales, constantes y otros

```{r}
PATH_DATOS <- "./data/bd_final.csv"
SEP_COLUMNAS <- ";"
SEP_DECIMAL <- "."

SEED <- 987
PORCENTAJE_TRAIN <- .8
VALOR_LAPLACE <- 1

VARIABLES_LOGISTICA <- c("diagnostico_pro", "d1", "d2", "d3", "d4", "d5", "edad", "id")
VARIABLES_BAYES <- c("id",
                     "d1", 
                     "es_cuidador",
                     "educ",
                     "empleo",
                     "estado_marital", 
                     "facilidad_celular",
                     "fumo",
                     "diagnostico_pro",
                     "F0semitoneFrom27.5Hz_sma3nz_amean",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevNorm",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile20.0",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile50.0",
                     "F0semitoneFrom27.5Hz_sma3nz_percentile80.0",
                     "F0semitoneFrom27.5Hz_sma3nz_pctlrange0.2",
                     "F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope",
                     "F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope",
                     "F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope",
                     "jitterLocal_sma3nz_amean",
                     "jitterLocal_sma3nz_stddevNorm", 
                     "shimmerLocaldB_sma3nz_amean", 
                     "shimmerLocaldB_sma3nz_stddevNorm")
```

# Cargar datos

```{r}
datos_crudos <- read.table(PATH_DATOS, sep = SEP_COLUMNAS, dec = SEP_DECIMAL, header = TRUE)
glimpse(datos_crudos)
```

Primero transfromamos todas las variables del tipo character como factores

```{r}

datos <- datos_crudos %>% 
  map_dfc(~ if(is.character(.x)) { factor(.x) } else { .x })

glimpse(datos)

```

# Regresión Logística

Vamos a armar una regresión logística con diagnostico_pro como respuesta y las variables d1, d2, d3, d4, d5 y edad como predictoras.

Observamos los NAs para las variables leegidas

```{r}
vector_cant_nas <- datos %>% 
  select(all_of(VARIABLES_LOGISTICA)) %>% 
  map_int(~ sum(is.na(.x)))

vector_cant_nas[vector_cant_nas > 0]
```

No se observan NAs en las variables a usar, ahora apartamos las varaibles que vamos a utilizar en el modelo.

```{r}
datos_log <- datos %>%
  select(all_of(VARIABLES_LOGISTICA))

glimpse(datos_log)
```
Dividimos los datos

```{r}
set.seed(SEED)
indices_train_log <- createDataPartition(datos_log$diagnostico_pro, 
                                         p = PORCENTAJE_TRAIN, 
                                         list = FALSE) %>% 
  as.vector()

datos_log_train <- datos_log[indices_train_log,]
datos_log_test <- datos_log[-indices_train_log,]

nrow(datos_log_train)
nrow(datos_log_test)
```
Entrenamos el modelo con las particiones

```{r}
modelo_log <- train(diagnostico_pro ~ .,
                    data = datos_log_train %>% select(-id),
                    method = "glm",
                    family= "binomial")

summary(modelo_log)
```

Observamos que solamente las variables d1, d2 y edad figuran con un pvalor significativo. Interpretamos uno de los resultados:

  * Por cada incremento de un año en la edad, hay un incremento promedio de `r round((exp(0.110494) - 1) * 100, 3)`% en los odds de tener un diagnóstico postivo de EP, manteniendo el resto de variables constantes.
  
Con el modelo elegido, vamos armar la curva ROC.

```{r}
graficar_curva_roc(modelo_log, datos_log_test, nivel_positivo = "true", var_respuesta = "diagnostico_pro")
```

Vamos a tratar de mejorar el AUC identificando observaciones influyentes para el modelo. Usamos la distancia de cook como métrica.


```{r}
data.frame(d_cook = cooks.distance(modelo_log$finalModel)) %>% arrange(- d_cook) %>% top_n(10)
```

Observamos que la observación 302 es la que se encuentra más alejada del resto, por lo que vamos a probar entrenando otro modelo sin esa observación. 

```{r}
nro_fila_influyente <- 302

# Observamos como es ese registro
datos_log[nro_fila_influyente,]

# Excluimos la observacion
datos_log_sin_inf <- datos_log[-nro_fila_influyente,]

# Realizamos la particion de vuelta
set.seed(SEED)
indices_train_inf <- createDataPartition(datos_log_sin_inf$diagnostico_pro, 
                                         p = PORCENTAJE_TRAIN, 
                                         list = FALSE) %>% 
  as.vector()

datos_log_inf_train <- datos_log_sin_inf[indices_train_inf,]
datos_log_inf_test <- datos_log_sin_inf[- indices_train_inf,]

# Verifiquemos que se cree correctamente
nrow(datos_log_inf_train)
nrow(datos_log_inf_test)

```

Habiendo hecho la partición, ajustamos el modelo

```{r}
modelo_log_inf <- train(diagnostico_pro ~ .,
                        datos_log_inf_train %>% select(-id),
                        method = "glm",
                        family = "binomial")

summary(modelo_log_inf)
```

Comparando con el primer modelo de logístico armado, los coeficientes son similares.

Armamos de nuevo la curva ROC

```{r}
graficar_curva_roc(modelo_log_inf, datos_log_inf_test, "true", "diagnostico_pro")
```

Se observa que el AUC es el mismo, así que no excluimos esa observación. 

Ahora lo que hacemos es graficar specificity vs sensitivity para todos los posibles puntos de corte

```{r}
# Primero creamos un objeto roc
predicciones_log <- predict(modelo_log, datos_log_test, list = FALSE, type = "prob")
objeto_roc_log <- roc(datos_log_test$diagnostico_pro, predicciones_log[, "true"])


# Armamos el grafico
data.frame(Specificity = objeto_roc_log$specificities,
           Sencitivity = objeto_roc_log$sensitivities,
           Thresholds = objeto_roc_log$thresholds) %>% 
  ggplot(aes(x = Thresholds)) +
  geom_line(aes(y = Specificity), color = "firebrick") +
  geom_line(aes(y = Sencitivity), color = "orange") + 
  geom_vline(xintercept = .5, color = "gray") +
  geom_vline(xintercept = .4, color = "gray") +
  ylab("")
```
Observamos que el punto de intersección se encuentra en algún punto entre 0.4 y 0.5. Elegimos el punto 0.44 como punto de corte para armar una matriz de confusión.

```{r}

# Hacemos las predicciones usando 0.44 como punto de corte
prediccioes_log_matriz_confusion <- ifelse(predicciones_log[, "true"] >= 0.44,
                                           "true",
                                           "false") %>%
  as.factor()

# Armamos la matriz de confusion
confusionMatrix(prediccioes_log_matriz_confusion, 
                datos_log_test$diagnostico_pro, 
                positive = "true")

```

# Naive Bayes

```{r}
datos_bayes <- datos %>% 
  select(all_of(VARIABLES_BAYES))
glimpse(datos_bayes)
```

Primero observamos los NAs en las variables que vamos a usar en el modelo

```{r}
vector_cant_nas <- datos_bayes %>%
  map_int(~ sum(is.na(.x)))

vector_cant_nas[vector_cant_nas > 0] %>% sort(decreasing = TRUE)
```
Para tratar los NAs vamos a tomar dos caminos:

  * Vamos a hacer un modelo donde los NAs son sustitudos por el promedio o el nivel con mayor cantidad de observaciones.
  * Vamos a hacer un modelo donde se eliminen los registros con NAs.
  
```{r}
# Reemplazamos los NAs
datos_bayes_con_na <- datos_bayes %>% 
  mutate(es_cuidador = replace(es_cuidador, is.na(es_cuidador), "false"),
         educ = replace(educ, is.na(educ), "4-year college degree"),
         empleo = replace(empleo, is.na(empleo), "Employment for wages"),
         estado_marital = replace(estado_marital, is.na(estado_marital), "Married or domestic partnership"),
         facilidad_celular = replace(facilidad_celular, is.na(facilidad_celular), "Very easy"),
         fumo = replace(fumo, is.na(fumo), "false"))

# Elminamos los NAs
datos_bayes_sin_na <- datos_bayes %>% 
  drop_na()

# Vemos como quedaron los datasets
paste("Cantidad de observaciones en datos con NAs reemplazados:", nrow(datos_bayes_con_na))
paste("Cantidad de observaciones en datos con NAs eliminados:", nrow(datos_bayes_sin_na))

```

## Con NAs sustitudos

Empezamos haciendo las particiones

```{r}
set.seed(SEED)
indices_train_bayes <- createDataPartition(datos_bayes_con_na$diagnostico_pro, p = PORCENTAJE_TRAIN, list = FALSE) %>% 
  as.vector()

datos_bayes_con_na_train <- datos_bayes_con_na[indices_train_bayes, ]
datos_bayes_con_na_test <- datos_bayes_con_na[- indices_train_bayes, ]

nrow(datos_bayes_con_na_train)
nrow(datos_bayes_con_na_test)
```
Entrenamos el modelo con los datos de train

```{r}
modelo_bayes_con_na <- naiveBayes(diagnostico_pro ~ .,
                             data = datos_bayes_con_na_train %>% select(-id),
                             laplace = VALOR_LAPLACE)

modelo_bayes_con_na
                             
```

```{r}
graficar_curva_roc(modelo_bayes_con_na, 
                   datos_bayes_con_na_test, 
                   nivel_positivo = "true", 
                   var_respuesta = "diagnostico_pro", 
                   type_predict = "raw")
```
Vamos a tratar de mejorar está métrica, primero empecemos viendo si las variables numéricas se aproximan a una normal.

```{r}
nombres_variables <- datos_bayes_con_na %>% 
  select(where(is.numeric)) %>%
  names()
  
graficos <- datos_bayes_con_na %>% 
  select(where(is.numeric)) %>%
  map2(nombres_variables, ~ ggplot(datos_bayes_con_na, aes(.x, color = diagnostico_pro)) +
        geom_density(show.legend = FALSE) + 
         xlab(.y) +
         ylab(""))


ggarrange(plotlist = graficos)
```

Ahora comparamos los mismos resultados aplicando una transformación logarítmica a los datos, solo a las variables que no observemos una densidad muy aleajada de la normal.

```{r}

vars_trans_log <- c("F0semitoneFrom27.5Hz_sma3nz_amean", 
                    "shimmerLocaldB_sma3nz_amean",
                    "jitterLocal_sma3nz_amean")

graficos <- datos_bayes_con_na %>% 
  select(all_of(vars_trans_log)) %>%
  map2(vars_trans_log, ~ ggplot(datos_bayes_con_na, aes(log(.x), color = diagnostico_pro)) +
        geom_density(show.legend = FALSE) + 
         xlab(.y) +
         ylab(""))

ggarrange(plotlist = graficos)
```

Creamos un nuevo dataset con las variables transformadas

```{r}
datos_bayes_con_na_log <- datos_bayes_con_na %>% 
  mutate(F0semitoneFrom27.5Hz_sma3nz_amean = log(F0semitoneFrom27.5Hz_sma3nz_amean),
  shimmerLocaldB_sma3nz_amean = log(shimmerLocaldB_sma3nz_amean),
  jitterLocal_sma3nz_amean = log(jitterLocal_sma3nz_amean))
```

Volvemos a realizar la partición y entrenamos el modelo

```{r}
set.seed(SEED)
indices_train_bayes <- createDataPartition(datos_bayes_con_na_log$diagnostico_pro,
                                           p = PORCENTAJE_TRAIN,
                                           list = FALSE) %>% 
  as.vector()

datos_bayes_con_na_log_train <- datos_bayes_con_na_log[indices_train_bayes, ]
datos_bayes_con_na_log_test <- datos_bayes_con_na_log[-indices_train_bayes, ]

# Verificamos
nrow(datos_bayes_con_na_log) == nrow(datos_bayes_con_na_log_train) + nrow(datos_bayes_con_na_log_test)
```

Ahora entrenamos el modelo

```{r}
modelo_bayes_con_na_log <- naiveBayes(diagnostico_pro ~ .,
                                      datos_bayes_con_na_log_train %>% select(-id),
                                      laplace = VALOR_LAPLACE)

modelo_bayes_con_na_log
```
Dibujamos la curva ROC y AUROC

```{r}
graficar_curva_roc(modelo_bayes_con_na_log,
                   datos_bayes_con_na_log_test,
                   nivel_positivo = "true",
                   var_respuesta = "diagnostico_pro",
                   type_predict = "raw")
```
Para seguir tratando de mejorar el modelo vamos a re-organizar las categorías de las variables cualitativas, ya que hay varías que se encuentran con niveles desbalanceados.

```{r}
datos_bayes_con_na_refactor <- datos_bayes_con_na


# Dividir educ en Posgraduate - College - Highschool
datos_bayes_con_na_refactor <- datos_bayes_con_na_refactor %>% 
  mutate(educ = fct_collapse(educ,
                           "Postgraduate" = c("Doctoral Degree", "Masters Degree"),
                           "College" = c("2-year college degree", "4-year college degree", "Some graduate school"),
                           "HighSchool" = c("High School Diploma/GED", "Some college", "Some high school")))

# Emplemos lo agrupamos en Working - Not Working
datos_bayes_con_na_refactor <- datos_bayes_con_na_refactor %>% 
  mutate(empleo = fct_collapse(empleo, 
                               "Working" = c("A homemaker", "Employment for wages", "Self-employed"),
                               "Not Working" = c("A student", "Out of work", "Retired", "Unable to work" )))

# Estado marital lo convertimos en Married - Not Married
datos_bayes_con_na_refactor <- datos_bayes_con_na_refactor %>% 
  mutate(estado_marital = fct_collapse(estado_marital,
                                       "Married" = c("Married or domestic partnership"),
                                       "Not Married" = c("Divorced", "Other", "Separated", "Single never married", "Widowed")))

# Para facilidad celular lo convertimos en Easy - Not Easy
datos_bayes_con_na_refactor <- datos_bayes_con_na_refactor %>% 
  mutate(facilidad_celular = fct_collapse(facilidad_celular,
                                    "Not Easy" = c("Difficult", "Neither easy nor difficult", "Very Difficult"),
                                    "Easy" = c("Easy", "Very easy")))
```


Volvemos a particionar, entrenar el modelo y graficar la curva ROC

```{r}
set.seed(SEED)
indices_train_bayes <- createDataPartition(datos_bayes_con_na_refactor$diagnostico_pro,
                                           p = PORCENTAJE_TRAIN,
                                           list = FALSE) %>% 
  as.vector()

datos_bayes_con_na_refactor_train <- datos_bayes_con_na_refactor[indices_train_bayes,]
datos_bayes_con_na_refactor_test <- datos_bayes_con_na_refactor[-indices_train_bayes,]

# Verificamos
nrow(datos_bayes_con_na_refactor) == nrow(datos_bayes_con_na_refactor_train) + nrow(datos_bayes_con_na_refactor_test)
```

```{r}
modelo_bayes_con_na_refactor <- naiveBayes(diagnostico_pro ~ .,
                                           datos_bayes_con_na_refactor_train %>% select(-id),
                                           laplace = VALOR_LAPLACE)

modelo_bayes_con_na_refactor
```
```{r}
graficar_curva_roc(modelo_bayes_con_na_refactor, 
                   datos_bayes_con_na_refactor_test, 
                   nivel_positivo = "true", 
                   var_respuesta = "diagnostico_pro", 
                   type_predict = "raw")
```

Empeoro el AUC en este caso

Por último, probamos un modelo en un dataset que incluye tanto las transformaciones logaritmicas como la reorganización de los factores.

```{r}
variables_categoricas <- datos_bayes_con_na_refactor %>% select(where(is.factor))
variables_cuanti <- datos_bayes_con_na_log %>% select(where(is.numeric))
datos_bayes_con_na_log_refactor <- cbind(variables_categoricas, variables_cuanti)

# Para verificar
nrow(datos_bayes_con_na_log_refactor) == nrow(datos_bayes)
ncol(datos_bayes_con_na_log_refactor) == ncol(datos_bayes)
```

```{r}
set.seed(SEED)
indices_train_bayes <- createDataPartition(datos_bayes_con_na_log_refactor$diagnostico_pro, 
                                           p = PORCENTAJE_TRAIN,
                                           list = FALSE) %>% 
  as.vector()

datos_bayes_con_na_log_refactor_train <- datos_bayes_con_na_log_refactor[indices_train_bayes,]
datos_bayes_con_na_log_refactor_test <- datos_bayes_con_na_log_refactor[-indices_train_bayes,]

# Verificacion
nrow(datos_bayes_con_na_log_refactor) == nrow(datos_bayes_con_na_log_refactor_train) + nrow(datos_bayes_con_na_log_refactor_test)
```

```{r}
modelo_bayes_con_na_log_refactor <- naiveBayes(diagnostico_pro ~ .,
                                               datos_bayes_con_na_log_refactor_train %>% select(-id),
                                               laplace = VALOR_LAPLACE)
modelo_bayes_con_na_log_refactor
```
```{r}
graficar_curva_roc(modelo_bayes_con_na_log_refactor,
                   datos_bayes_con_na_log_refactor_test, nivel_positivo = "true", 
                   var_respuesta = "diagnostico_pro", 
                   type_predict = "raw")
```


## Con NAs eliminados

Realizamos la partición

```{r}
set.seed(SEED)
indices_train_bayes <- createDataPartition(datos_bayes_sin_na$diagnostico_pro, p = PORCENTAJE_TRAIN,  list = FALSE) %>% 
  as.vector()

datos_bayes_sin_na_train <- datos_bayes_sin_na[indices_train_bayes, ]
datos_bayes_sin_na_test <- datos_bayes_sin_na[- indices_train_bayes, ]

# Verificamos
nrow(datos_bayes_sin_na) == nrow(datos_bayes_sin_na_train) + nrow(datos_bayes_sin_na_test)
```
Ahora ajustamos el modelo

```{r}
modelo_bayes_sin_na <- naiveBayes(diagnostico_pro ~ .,
                                  datos_bayes_sin_na_train %>% select(-id),
                                  laplace = VALOR_LAPLACE)

modelo_bayes_sin_na
```
Graficamos la cruva ROC

```{r}
graficar_curva_roc(modelo_bayes_sin_na, 
                   datos_bayes_sin_na_test,
                   nivel_positivo = "true", 
                   var_respuesta = "diagnostico_pro",
                   type_predict = "raw")
```

# Evaluación de los modelos

```{r}
proporciones <- seq(0.05, .35, .05)
```


## Regresión Logística

```{r}
evaluar_modelo_metodo_silvia(modelo_log, 
                             datos_log, 
                             proporciones, 
                             nombre_var_respuesta = "diagnostico_pro", 
                             nombre_var_ids = "id") 

#aux <- crear_df_evaluacion(modelo_log, 
#                    datos_log, nombre_var_respuesta = "diagnostico_pro", nombre_var_ids = "id", nivel_positivo = "true", type_predict = "prob")
```

## Naive Bayes

Primero corremos el mejor modelo de bayes con los NAs reemplazados.

```{r}
evaluar_modelo_metodo_silvia(modelo_bayes_con_na_log, 
                             datos_bayes_con_na_log, 
                             proporciones, 
                             nombre_var_respuesta = "diagnostico_pro", 
                             nombre_var_ids = "id", 
                             type_predict = "raw")


#crear_df_evaluacion(modelo_bayes_con_na_log, 
#                             datos_bayes_con_na_log, 
#                             nombre_var_respuesta = "diagnostico_pro", 
#                             nombre_var_ids = "id", 
#                             type_predict = "raw", 
#                  nivel_positivo = "true")

```

Ahora corremos el modelo de bayes con los NAs eliminados

```{r}
evaluar_modelo_metodo_silvia(modelo_bayes_sin_na, 
                             datos_bayes_sin_na, 
                             proporciones, 
                             nombre_var_respuesta = "diagnostico_pro", 
                             nombre_var_ids = "id", 
                             type_predict = "raw")
```

